"""
éŸ³å£°å‡¦ç†ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
Librosaã‚’ä½¿ç”¨ã—ãŸéŸ³å£°åˆ†ææ©Ÿèƒ½ã‚’æä¾›
"""

import librosa
import numpy as np
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from scipy.spatial.distance import euclidean
from fastdtw import fastdtw


class AudioProcessor:
    """éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†ã¨åˆ†æã‚’è¡Œã†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, sample_rate: int = 22050):
        """
        Parameters:
        - sample_rate: ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆï¼ˆHzï¼‰
        """
        self.sample_rate = sample_rate
    
    def load_audio(self, file_path: str) -> Tuple[np.ndarray, int]:
        """
        éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
        
        Returns:
        - audio_data: éŸ³å£°ãƒ‡ãƒ¼ã‚¿ï¼ˆnumpyé…åˆ—ï¼‰
        - sample_rate: ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆ
        """
        import warnings
        warnings.filterwarnings('ignore')
        
        print(f"load_audioå‘¼ã³å‡ºã—: file_path={file_path}, type={type(file_path)}")
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
        if not Path(file_path).exists():
            raise FileNotFoundError(f"Audio file not found: {file_path}")
        
        # ãƒ•ã‚¡ã‚¤ãƒ«æ‹¡å¼µå­ã‚’å–å¾—
        file_extension = Path(file_path).suffix.lower()
        print(f"ãƒ•ã‚¡ã‚¤ãƒ«æ‹¡å¼µå­: {file_extension}")
        
        # 3GP/AMRãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆã€FFmpegã§å¤‰æ›
        if file_extension in ['.3gp', '.amr']:
            try:
                import subprocess
                import tempfile
                import os
                
                print(f"3GP/AMRãƒ•ã‚¡ã‚¤ãƒ«ã‚’å¤‰æ›ä¸­: {file_path}")
                
                # ä¸€æ™‚WAVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
                temp_wav = tempfile.mktemp(suffix='.wav')
                
                # FFmpegã§å¤‰æ›ï¼ˆã‚ˆã‚Šå …ç‰¢ãªæ–¹æ³•ï¼‰
                try:
                    result = subprocess.run([
                        'ffmpeg', '-i', file_path,
                        '-ar', str(self.sample_rate),
                        '-ac', '1',
                        '-y',
                        temp_wav
                    ], check=True, capture_output=True, text=True, timeout=30)
                    print(f"FFmpegå¤‰æ›æˆåŠŸ")
                except subprocess.CalledProcessError as e:
                    print(f"FFmpegå¤‰æ›ã‚¨ãƒ©ãƒ¼: {e.stderr}")
                    raise Exception(f"FFmpeg conversion failed: {e.stderr}")
                except FileNotFoundError:
                    print("FFmpegãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚pydubã§è©¦ã—ã¾ã™ã€‚")
                    # pydubã§å¤‰æ›ã‚’è©¦ã¿ã‚‹
                    from pydub import AudioSegment
                    audio = AudioSegment.from_file(file_path)
                    audio = audio.set_channels(1)
                    audio = audio.set_frame_rate(self.sample_rate)
                    audio.export(temp_wav, format="wav")
                    print(f"pydubå¤‰æ›æˆåŠŸ")
                
                # WAVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
                audio_data, sr = librosa.load(temp_wav, sr=self.sample_rate, mono=True)
                
                # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
                if os.path.exists(temp_wav):
                    os.remove(temp_wav)
                
                print(f"3GP/AMRå¤‰æ›æˆåŠŸ: {len(audio_data)} samples")
                return audio_data, sr
                
            except Exception as e:
                print(f"Error converting 3GP/AMR: {e}")
                import traceback
                print(traceback.format_exc())
                raise Exception(f"Failed to convert 3GP/AMR file: {str(e)}")
        
        # WAVãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆã€scipyã§è©¦ã™ï¼ˆè»½é‡ï¼‰
        if file_extension == '.wav':
            try:
                from scipy.io import wavfile
                sr, audio_data = wavfile.read(file_path)
                print(f"scipyèª­ã¿è¾¼ã¿æˆåŠŸ: sr={sr}, shape={audio_data.shape}, dtype={audio_data.dtype}")
                
                # æ­£è¦åŒ–
                if audio_data.dtype == np.int16:
                    audio_data = audio_data.astype(np.float32) / 32768.0
                elif audio_data.dtype == np.int32:
                    audio_data = audio_data.astype(np.float32) / 2147483648.0
                elif audio_data.dtype == np.uint8:
                    audio_data = (audio_data.astype(np.float32) - 128) / 128.0
                
                # ãƒ¢ãƒãƒ©ãƒ«ã«å¤‰æ›
                if len(audio_data.shape) > 1:
                    audio_data = np.mean(audio_data, axis=1)
                
                # ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
                if sr != self.sample_rate:
                    audio_data = librosa.resample(audio_data, orig_sr=sr, target_sr=self.sample_rate)
                
                print(f"scipyå‡¦ç†å®Œäº†: æœ€çµ‚shape={audio_data.shape}")
                return audio_data, self.sample_rate
            except Exception as e:
                print(f"scipyèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
                # æ¬¡ã®æ–¹æ³•ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        
        # MP3, M4A, OGG, FLACãªã©ã®å ´åˆã€soundfileã¾ãŸã¯librosaã§èª­ã¿è¾¼ã¿
        try:
            import soundfile as sf
            audio_data, sr = sf.read(file_path, dtype='float32')
            print(f"soundfileèª­ã¿è¾¼ã¿æˆåŠŸ: sr={sr}, shape={audio_data.shape}")
            
            # ãƒ¢ãƒãƒ©ãƒ«ã«å¤‰æ›
            if len(audio_data.shape) > 1:
                audio_data = np.mean(audio_data, axis=1)
            
            # ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
            if sr != self.sample_rate:
                audio_data = librosa.resample(audio_data, orig_sr=sr, target_sr=self.sample_rate)
            
            print(f"soundfileå‡¦ç†å®Œäº†: æœ€çµ‚shape={audio_data.shape}")
            return audio_data, self.sample_rate
        except Exception as e:
            print(f"soundfileèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            
            # æœ€çµ‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šlibrosaã§èª­ã¿è¾¼ã¿ï¼ˆæœ€ã‚‚æ±ç”¨çš„ã ãŒé…ã„ï¼‰
            try:
                audio_data, sr = librosa.load(file_path, sr=self.sample_rate, mono=True)
                print(f"librosaèª­ã¿è¾¼ã¿æˆåŠŸ: shape={audio_data.shape}")
                return audio_data, self.sample_rate
            except Exception as e2:
                print(f"librosaèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e2}")
                raise Exception(f"Could not load audio file with any method. File: {file_path}, Extension: {file_extension}. Errors: {str(e)}, {str(e2)}")
    
    def extract_features(self, audio_data: np.ndarray) -> Dict:
        """
        éŸ³å£°ã‹ã‚‰ç‰¹å¾´é‡ã‚’æŠ½å‡º
        
        Returns:
        - features: æŠ½å‡ºã•ã‚ŒãŸç‰¹å¾´é‡ã®è¾æ›¸
        """
        features = {}
        
        # MFCC (Mel-frequency cepstral coefficients)
        mfcc = librosa.feature.mfcc(y=audio_data, sr=self.sample_rate, n_mfcc=13)
        features['mfcc'] = mfcc
        features['mfcc_mean'] = np.mean(mfcc, axis=1)
        features['mfcc_std'] = np.std(mfcc, axis=1)
        
        # ãƒ”ãƒƒãƒï¼ˆåŸºæœ¬å‘¨æ³¢æ•°ï¼‰
        pitches, magnitudes = librosa.piptrack(y=audio_data, sr=self.sample_rate)
        pitch_values = []
        for t in range(pitches.shape[1]):
            index = magnitudes[:, t].argmax()
            pitch = pitches[index, t]
            if pitch > 0:
                pitch_values.append(pitch)
        
        features['pitch_mean'] = np.mean(pitch_values) if pitch_values else 0
        features['pitch_std'] = np.std(pitch_values) if pitch_values else 0
        
        # ã‚¹ãƒšã‚¯ãƒˆãƒ«é‡å¿ƒ
        spectral_centroids = librosa.feature.spectral_centroid(y=audio_data, sr=self.sample_rate)[0]
        features['spectral_centroid_mean'] = np.mean(spectral_centroids)
        features['spectral_centroid_std'] = np.std(spectral_centroids)
        
        # ã‚¼ãƒ­äº¤å·®ç‡
        zero_crossing_rate = librosa.feature.zero_crossing_rate(audio_data)[0]
        features['zero_crossing_rate_mean'] = np.mean(zero_crossing_rate)
        
        # RMS ã‚¨ãƒãƒ«ã‚®ãƒ¼
        rms = librosa.feature.rms(y=audio_data)[0]
        features['rms_mean'] = np.mean(rms)
        features['rms_std'] = np.std(rms)
        
        # éŸ³å£°ã®é•·ã•
        features['duration'] = len(audio_data) / self.sample_rate
        
        return features
    
    def analyze_pronunciation(self, file_path: str) -> Dict:
        """
        ç™ºéŸ³ã‚’åˆ†æã—ã¦è©•ä¾¡ã‚’è¿”ã™
        
        Returns:
        - analysis: åˆ†æçµæœã®è¾æ›¸
        """
        # éŸ³å£°ã‚’èª­ã¿è¾¼ã¿
        audio_data, sr = self.load_audio(file_path)
        
        # ç‰¹å¾´é‡ã‚’æŠ½å‡º
        features = self.extract_features(audio_data)
        
        # TODO: æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ãŸå®Ÿéš›ã®ç™ºéŸ³è©•ä¾¡ã‚’å®Ÿè£…
        # ç¾åœ¨ã¯ãƒ€ãƒŸãƒ¼ã®åˆ†æçµæœã‚’è¿”ã™
        
        analysis = {
            "duration": features['duration'],
            "pitch_mean": float(features['pitch_mean']),
            "pitch_std": float(features['pitch_std']),
            "spectral_centroid_mean": float(features['spectral_centroid_mean']),
            "rms_mean": float(features['rms_mean']),
            "features_extracted": True
        }
        
        return analysis
    
    def calculate_dtw_similarity(
        self,
        user_mfcc: np.ndarray,
        reference_mfcc: np.ndarray
    ) -> float:
        """
        DTWï¼ˆå‹•çš„æ™‚é–“ä¼¸ç¸®æ³•ï¼‰ã‚’ä½¿ç”¨ã—ã¦MFCCç‰¹å¾´é‡ã®é¡ä¼¼åº¦ã‚’è¨ˆç®—
        
        Parameters:
        - user_mfcc: ãƒ¦ãƒ¼ã‚¶ãƒ¼éŸ³å£°ã®MFCC
        - reference_mfcc: å‚ç…§éŸ³å£°ã®MFCC
        
        Returns:
        - similarity_score: é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢ï¼ˆ0-100ï¼‰
        """
        # MFCCã‚’è»¢ç½®ï¼ˆæ™‚é–“è»¸ã‚’ç¬¬ä¸€æ¬¡å…ƒã«ï¼‰
        user_mfcc_t = user_mfcc.T
        reference_mfcc_t = reference_mfcc.T
        
        # DTWã§è·é›¢ã‚’è¨ˆç®—
        distance, _ = fastdtw(user_mfcc_t, reference_mfcc_t, dist=euclidean)
        
        print(f"DTWè·é›¢: {distance}")
        
        # è·é›¢ã‚’é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢ã«å¤‰æ›ï¼ˆ0-100ã®ç¯„å›²ï¼‰
        # è·é›¢ãŒå°ã•ã„ã»ã©é¡ä¼¼åº¦ãŒé«˜ã„
        # éå¸¸ã«å³ã—ã„åŸºæº–:
        # - ç´ æ™´ã‚‰ã—ã„: 2500ä»¥ä¸‹ â†’ 85-100ç‚¹
        # - è‰¯ã„: 2500-6000 â†’ 70-85ç‚¹
        # - ã¾ã‚ã¾ã‚: 6000-12000 â†’ 50-70ç‚¹
        # - è¦æ”¹å–„: 12000-20000 â†’ 30-50ç‚¹
        # - æ‚ªã„: 20000-30000 â†’ 10-30ç‚¹
        # - ä¸åˆæ ¼: 30000ä»¥ä¸Š â†’ 0-10ç‚¹
        
        if distance < 2500:
            # ç´ æ™´ã‚‰ã—ã„ç™ºéŸ³ï¼ˆãƒã‚¤ãƒ†ã‚£ãƒ–ã«è¿‘ã„ï¼‰
            similarity_score = 85 + (1 - distance / 2500) * 15
        elif distance < 6000:
            # è‰¯ã„ç™ºéŸ³
            similarity_score = 70 + (1 - (distance - 2500) / 3500) * 15
        elif distance < 12000:
            # ã¾ã‚ã¾ã‚
            similarity_score = 50 + (1 - (distance - 6000) / 6000) * 20
        elif distance < 20000:
            # è¦æ”¹å–„
            similarity_score = 30 + (1 - (distance - 12000) / 8000) * 20
        elif distance < 30000:
            # æ‚ªã„ï¼ˆæ‰‹æœ¬ã¨å¤§ããç•°ãªã‚‹ï¼‰
            similarity_score = 10 + (1 - (distance - 20000) / 10000) * 20
        else:
            # ä¸åˆæ ¼ï¼ˆç„¡éŸ³ã¾ãŸã¯å…¨ãé•ã†ç™ºéŸ³ï¼‰
            similarity_score = max(0, 10 - (distance - 30000) / 5000)
        
        print(f"ã‚¹ã‚³ã‚¢: {similarity_score:.2f}")
        
        return float(max(0, min(100, similarity_score)))
    
    def compare_pronunciation(
        self,
        user_audio_path: str,
        reference_audio_path: str,
        user_level: str = "beginner"
    ) -> Dict:
        """
        ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™ºéŸ³ã¨å‚ç…§éŸ³å£°ã‚’æ¯”è¼ƒï¼ˆDTWãƒ™ãƒ¼ã‚¹ï¼‰
        
        Parameters:
        - user_audio_path: ãƒ¦ãƒ¼ã‚¶ãƒ¼éŸ³å£°ã®ãƒ‘ã‚¹
        - reference_audio_path: å‚ç…§éŸ³å£°ã®ãƒ‘ã‚¹
        - user_level: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ¬ãƒ™ãƒ«ï¼ˆbeginner/intermediate/advancedï¼‰
        
        Returns:
        - comparison: æ¯”è¼ƒçµæœ
        """
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼éŸ³å£°ã‚’èª­ã¿è¾¼ã¿
        user_audio, _ = self.load_audio(user_audio_path)
        user_features = self.extract_features(user_audio)
        
        # ç„¡éŸ³æ¤œå‡ºï¼šRMSã‚¨ãƒãƒ«ã‚®ãƒ¼ãŒéå¸¸ã«ä½ã„å ´åˆã¯0ç‚¹
        if user_features['rms_mean'] < 0.001:
            print(f"ç„¡éŸ³æ¤œå‡º: RMS={user_features['rms_mean']}")
            # å‚ç…§éŸ³å£°ã‚‚èª­ã¿è¾¼ã‚“ã§ç‰¹å¾´é‡ã‚’å–å¾—ï¼ˆãƒ¬ã‚¹ãƒãƒ³ã‚¹ç”¨ï¼‰
            reference_audio, _ = self.load_audio(reference_audio_path)
            reference_features = self.extract_features(reference_audio)
            
            feedback = self.generate_feedback(
                0,  # ã‚¹ã‚³ã‚¢0
                user_features,
                reference_features,
                user_level
            )
            
            return {
                "similarity_score": 0,
                "user_features": {
                    "duration": float(user_features['duration']),
                    "pitch_mean": float(user_features['pitch_mean']),
                    "pitch_std": float(user_features['pitch_std']),
                },
                "reference_features": {
                    "duration": float(reference_features['duration']),
                    "pitch_mean": float(reference_features['pitch_mean']),
                    "pitch_std": float(reference_features['pitch_std']),
                },
                "feedback": feedback,
                "level": user_level
            }
        
        # å‚ç…§éŸ³å£°ã‚’èª­ã¿è¾¼ã¿
        reference_audio, _ = self.load_audio(reference_audio_path)
        reference_features = self.extract_features(reference_audio)
        
        # DTWã§é¡ä¼¼åº¦ã‚’è¨ˆç®—
        dtw_score = self.calculate_dtw_similarity(
            user_features['mfcc'],
            reference_features['mfcc']
        )
        
        print(f"DTWã‚¹ã‚³ã‚¢: {dtw_score:.2f}")
        
        # ãƒ”ãƒƒãƒã®å·®ã‚’ãƒšãƒŠãƒ«ãƒ†ã‚£ã¨ã—ã¦è¨ˆç®—
        pitch_diff = abs(user_features['pitch_mean'] - reference_features['pitch_mean'])
        pitch_diff_percent = (pitch_diff / reference_features['pitch_mean'] * 100) if reference_features['pitch_mean'] > 0 else 0
        pitch_penalty = min(30, pitch_diff_percent / 2)  # æœ€å¤§30ç‚¹æ¸›ç‚¹
        print(f"ãƒ”ãƒƒãƒå·®: {pitch_diff:.2f}Hz ({pitch_diff_percent:.1f}%), ãƒšãƒŠãƒ«ãƒ†ã‚£: {pitch_penalty:.1f}ç‚¹")
        
        # éŸ³é‡ã®å·®ã‚’ãƒšãƒŠãƒ«ãƒ†ã‚£ã¨ã—ã¦è¨ˆç®—
        rms_diff = abs(user_features['rms_mean'] - reference_features['rms_mean'])
        rms_diff_percent = (rms_diff / reference_features['rms_mean'] * 100) if reference_features['rms_mean'] > 0 else 0
        rms_penalty = min(20, rms_diff_percent / 3)  # æœ€å¤§20ç‚¹æ¸›ç‚¹
        print(f"éŸ³é‡å·®: {rms_diff:.4f} ({rms_diff_percent:.1f}%), ãƒšãƒŠãƒ«ãƒ†ã‚£: {rms_penalty:.1f}ç‚¹")
        
        # é•·ã•ã®å·®ã‚’ãƒšãƒŠãƒ«ãƒ†ã‚£ã¨ã—ã¦è¨ˆç®—
        duration_diff = abs(user_features['duration'] - reference_features['duration'])
        duration_diff_percent = (duration_diff / reference_features['duration'] * 100) if reference_features['duration'] > 0 else 0
        duration_penalty = min(20, duration_diff_percent / 2)  # æœ€å¤§20ç‚¹æ¸›ç‚¹
        print(f"é•·ã•å·®: {duration_diff:.2f}ç§’ ({duration_diff_percent:.1f}%), ãƒšãƒŠãƒ«ãƒ†ã‚£: {duration_penalty:.1f}ç‚¹")
        
        # ç·åˆã‚¹ã‚³ã‚¢ = DTWã‚¹ã‚³ã‚¢ - ãƒšãƒŠãƒ«ãƒ†ã‚£
        total_penalty = pitch_penalty + rms_penalty + duration_penalty
        similarity_score = max(0, dtw_score - total_penalty)
        print(f"ç·åˆãƒšãƒŠãƒ«ãƒ†ã‚£: {total_penalty:.1f}ç‚¹")
        print(f"æœ€çµ‚ã‚¹ã‚³ã‚¢: {similarity_score:.2f} (DTW: {dtw_score:.2f} - ãƒšãƒŠãƒ«ãƒ†ã‚£: {total_penalty:.1f})")
        
        # ãƒ¬ãƒ™ãƒ«ã«å¿œã˜ãŸãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ç”Ÿæˆ
        feedback = self.generate_feedback(
            similarity_score,
            user_features,
            reference_features,
            user_level
        )
        
        comparison = {
            "similarity_score": round(similarity_score, 2),
            "user_features": {
                "duration": float(user_features['duration']),
                "pitch_mean": float(user_features['pitch_mean']),
                "pitch_std": float(user_features['pitch_std']),
            },
            "reference_features": {
                "duration": float(reference_features['duration']),
                "pitch_mean": float(reference_features['pitch_mean']),
                "pitch_std": float(reference_features['pitch_std']),
            },
            "feedback": feedback,
            "level": user_level
        }
        
        return comparison
    
    def generate_feedback(
        self,
        similarity_score: float,
        user_features: Dict,
        reference_features: Dict,
        user_level: str
    ) -> Dict:
        """
        ãƒ¬ãƒ™ãƒ«ã«å¿œã˜ãŸãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ç”Ÿæˆ
        
        Parameters:
        - similarity_score: é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢ï¼ˆ0-100ï¼‰
        - user_features: ãƒ¦ãƒ¼ã‚¶ãƒ¼éŸ³å£°ã®ç‰¹å¾´é‡
        - reference_features: å‚ç…§éŸ³å£°ã®ç‰¹å¾´é‡
        - user_level: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ¬ãƒ™ãƒ«
        
        Returns:
        - feedback: ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯è¾æ›¸
        """
        # æ˜ç¢ºãªè©•ä¾¡åŸºæº–ï¼ˆå…¨ãƒ¬ãƒ™ãƒ«å…±é€šï¼‰
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒç†è§£ã—ã‚„ã™ã„ã‚·ãƒ³ãƒ—ãƒ«ãªåŸºæº–
        if similarity_score >= 85:
            overall_rating = "ç´ æ™´ã‚‰ã—ã„"
            overall_message = "âœ¨ ç´ æ™´ã‚‰ã—ã„ç™ºéŸ³ã§ã™ï¼ãƒã‚¤ãƒ†ã‚£ãƒ–ã«è¿‘ã„ç™ºéŸ³ãŒã§ãã¦ã„ã¾ã™ã€‚"
            rating_emoji = "ğŸŒŸ"
        elif similarity_score >= 70:
            overall_rating = "è‰¯ã„"
            overall_message = "ğŸ‘ è‰¯ã„ç™ºéŸ³ã§ã™ï¼ã“ã®èª¿å­ã§ç·´ç¿’ã‚’ç¶šã‘ã¾ã—ã‚‡ã†ã€‚"
            rating_emoji = "ğŸ˜Š"
        elif similarity_score >= 50:
            overall_rating = "ã¾ã‚ã¾ã‚"
            overall_message = "ğŸ“ ã¾ã‚ã¾ã‚ã®ç™ºéŸ³ã§ã™ã€‚ä¸‹è¨˜ã®è©³ç´°ã‚’å‚è€ƒã«æ”¹å–„ã—ã¾ã—ã‚‡ã†ã€‚"
            rating_emoji = "ğŸ¤”"
        elif similarity_score >= 30:
            overall_rating = "è¦æ”¹å–„"
            overall_message = "ğŸ’ª ç·´ç¿’ãŒå¿…è¦ã§ã™ã€‚ä¸‹è¨˜ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã«æ³¨æ„ã—ã¦ãã ã•ã„ã€‚"
            rating_emoji = "ğŸ˜“"
        else:
            overall_rating = "ä¸åˆæ ¼"
            overall_message = "âŒ ç™ºéŸ³ãŒå¤§ããç•°ãªã‚Šã¾ã™ã€‚å‚ç…§éŸ³å£°ã‚’ã‚ˆãèã„ã¦ã€ç¹°ã‚Šè¿”ã—ç·´ç¿’ã—ã¦ãã ã•ã„ã€‚"
            rating_emoji = "ğŸ˜¢"
        
        # è©³ç´°ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ç”Ÿæˆ
        details = []
        
        # ã‚¹ã‚³ã‚¢ã«å¿œã˜ãŸãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ¬ãƒ™ãƒ«
        is_very_low_score = similarity_score < 30  # éå¸¸ã«æ‚ªã„
        is_low_score = 30 <= similarity_score < 50  # æ‚ªã„
        is_medium_score = 50 <= similarity_score < 70  # æ™®é€š
        
        # ãƒ”ãƒƒãƒã®æ¯”è¼ƒ
        pitch_diff = abs(user_features['pitch_mean'] - reference_features['pitch_mean'])
        pitch_diff_percent = (pitch_diff / reference_features['pitch_mean'] * 100) if reference_features['pitch_mean'] > 0 else 0
        
        # ãƒ”ãƒƒãƒã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ï¼ˆ0-100ï¼‰
        pitch_score = max(0, min(100, 100 - pitch_diff_percent))
        
        # ç·åˆã‚¹ã‚³ã‚¢ãŒä½ã„å ´åˆã¯ã€ãƒ”ãƒƒãƒã‚¹ã‚³ã‚¢ã‚‚å³ã—ãè©•ä¾¡
        if is_very_low_score:
            pitch_score = min(pitch_score, 29)  # æœ€å¤§29ç‚¹
        elif is_low_score:
            pitch_score = min(pitch_score, 49)  # æœ€å¤§49ç‚¹
        
        # ãƒ”ãƒƒãƒã‚¹ã‚³ã‚¢ã«åŸºã¥ã„ã¦ã‚³ãƒ¡ãƒ³ãƒˆã‚’ç”Ÿæˆ
        if pitch_score >= 70:
            pitch_comment = "âœ… ãƒ”ãƒƒãƒãŒè‰¯ã„ã§ã™ï¼"
        elif pitch_score >= 50:
            if user_features['pitch_mean'] > reference_features['pitch_mean']:
                pitch_comment = "âš ï¸ ãƒ”ãƒƒãƒãŒå°‘ã—é«˜ã‚ã§ã™ã€‚ã‚‚ã†å°‘ã—ä½ãè©±ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚"
            else:
                pitch_comment = "âš ï¸ ãƒ”ãƒƒãƒãŒå°‘ã—ä½ã‚ã§ã™ã€‚ã‚‚ã†å°‘ã—é«˜ãè©±ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚"
        else:
            if user_features['pitch_mean'] > reference_features['pitch_mean']:
                pitch_comment = "âŒ ãƒ”ãƒƒãƒãŒé•ã„ã¾ã™ã€‚å£°ãŒé«˜ã™ãã¾ã™ã€‚å‚ç…§éŸ³å£°ã®ã‚ˆã†ã«ä½ãè©±ã—ã¦ãã ã•ã„ã€‚"
            else:
                pitch_comment = "âŒ ãƒ”ãƒƒãƒãŒé•ã„ã¾ã™ã€‚å£°ãŒä½ã™ãã¾ã™ã€‚å‚ç…§éŸ³å£°ã®ã‚ˆã†ã«é«˜ãè©±ã—ã¦ãã ã•ã„ã€‚"
        
        details.append({
            "aspect": "ãƒ”ãƒƒãƒ",
            "comment": pitch_comment,
            "score": round(pitch_score, 1)
        })
        
        # éŸ³å£°ã®é•·ã•ï¼ˆã‚¿ã‚¤ãƒŸãƒ³ã‚°ï¼‰ã®æ¯”è¼ƒ
        duration_diff = abs(user_features['duration'] - reference_features['duration'])
        duration_diff_percent = (duration_diff / reference_features['duration'] * 100) if reference_features['duration'] > 0 else 0
        
        # ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ï¼ˆ0-100ï¼‰
        timing_score = max(0, min(100, 100 - duration_diff_percent))
        
        # ç·åˆã‚¹ã‚³ã‚¢ãŒä½ã„å ´åˆã¯ã€ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚¹ã‚³ã‚¢ã‚‚å³ã—ãè©•ä¾¡
        if is_very_low_score:
            timing_score = min(timing_score, 29)  # æœ€å¤§29ç‚¹
        elif is_low_score:
            timing_score = min(timing_score, 49)  # æœ€å¤§49ç‚¹
        
        # ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚¹ã‚³ã‚¢ã«åŸºã¥ã„ã¦ã‚³ãƒ¡ãƒ³ãƒˆã‚’ç”Ÿæˆ
        if timing_score >= 70:
            timing_comment = "âœ… ã‚¿ã‚¤ãƒŸãƒ³ã‚°ãŒç´ æ™´ã‚‰ã—ã„ã§ã™ï¼"
        elif timing_score >= 50:
            if user_features['duration'] > reference_features['duration']:
                timing_comment = "âš ï¸ å°‘ã—ã‚†ã£ãã‚Šè©±ã—ã¦ã„ã¾ã™ã€‚ãƒã‚¤ãƒ†ã‚£ãƒ–ã®ãƒšãƒ¼ã‚¹ã«åˆã‚ã›ã¦ã¿ã¾ã—ã‚‡ã†ã€‚"
            else:
                timing_comment = "âš ï¸ å°‘ã—æ—©å£ã§ã™ã€‚ã‚‚ã†å°‘ã—ã‚†ã£ãã‚Šè©±ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚"
        else:
            if user_features['duration'] > reference_features['duration']:
                timing_comment = "âŒ ã‚¿ã‚¤ãƒŸãƒ³ã‚°ãŒé•ã„ã¾ã™ã€‚ã‹ãªã‚Šã‚†ã£ãã‚Šè©±ã—ã¦ã„ã¾ã™ã€‚å‚ç…§éŸ³å£°ã®ãƒšãƒ¼ã‚¹ã«åˆã‚ã›ã¦ãã ã•ã„ã€‚"
            else:
                timing_comment = "âŒ ã‚¿ã‚¤ãƒŸãƒ³ã‚°ãŒé•ã„ã¾ã™ã€‚ã‹ãªã‚Šæ—©å£ã§ã™ã€‚å‚ç…§éŸ³å£°ã®ã‚ˆã†ã«ã‚†ã£ãã‚Šè©±ã—ã¦ãã ã•ã„ã€‚"
        
        details.append({
            "aspect": "ã‚¿ã‚¤ãƒŸãƒ³ã‚°",
            "comment": timing_comment,
            "score": round(timing_score, 1)
        })
        
        # ã‚¨ãƒãƒ«ã‚®ãƒ¼ï¼ˆéŸ³é‡ï¼‰ã®æ¯”è¼ƒ
        rms_diff = abs(user_features['rms_mean'] - reference_features['rms_mean'])
        rms_diff_percent = (rms_diff / reference_features['rms_mean'] * 100) if reference_features['rms_mean'] > 0 else 0
        
        # éŸ³é‡ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ï¼ˆ0-100ï¼‰
        volume_score = max(0, min(100, 100 - rms_diff_percent))
        
        # ç·åˆã‚¹ã‚³ã‚¢ãŒä½ã„å ´åˆã¯ã€éŸ³é‡ã‚¹ã‚³ã‚¢ã‚‚å³ã—ãè©•ä¾¡
        if is_very_low_score:
            volume_score = min(volume_score, 29)  # æœ€å¤§29ç‚¹
        elif is_low_score:
            volume_score = min(volume_score, 49)  # æœ€å¤§49ç‚¹
        
        # éŸ³é‡ã‚¹ã‚³ã‚¢ã«åŸºã¥ã„ã¦ã‚³ãƒ¡ãƒ³ãƒˆã‚’ç”Ÿæˆ
        if volume_score >= 70:
            volume_comment = "âœ… éŸ³é‡ãŒè‰¯ã„ã§ã™ï¼"
        elif volume_score >= 50:
            if user_features['rms_mean'] > reference_features['rms_mean']:
                volume_comment = "âš ï¸ ã‚‚ã†å°‘ã—å°ã•ãªå£°ã§è©±ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚"
            else:
                volume_comment = "âš ï¸ ã‚‚ã†å°‘ã—å¤§ããªå£°ã§ã¯ã£ãã‚Šã¨è©±ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚"
        else:
            if user_features['rms_mean'] > reference_features['rms_mean']:
                volume_comment = "âŒ éŸ³é‡ãŒé•ã„ã¾ã™ã€‚å£°ãŒå¤§ãã™ãã¾ã™ã€‚å‚ç…§éŸ³å£°ã®ã‚ˆã†ã«å°ã•ãªå£°ã§è©±ã—ã¦ãã ã•ã„ã€‚"
            else:
                volume_comment = "âŒ éŸ³é‡ãŒé•ã„ã¾ã™ã€‚å£°ãŒå°ã•ã™ãã¾ã™ã€‚å‚ç…§éŸ³å£°ã®ã‚ˆã†ã«ã¯ã£ãã‚Šã¨è©±ã—ã¦ãã ã•ã„ã€‚"
        
        details.append({
            "aspect": "éŸ³é‡",
            "comment": volume_comment,
            "score": round(volume_score, 1)
        })
        
        # ã‚¹ã‚³ã‚¢ãŒéå¸¸ã«ä½ã„å ´åˆã¯ã€å…¨ä½“çš„ãªæ”¹å–„ç‚¹ã‚’è¿½åŠ 
        if is_very_low_score:
            details.append({
                "aspect": "å…¨ä½“è©•ä¾¡",
                "comment": "âŒ ç™ºéŸ³ãŒå‚ç…§éŸ³å£°ã¨å¤§ããç•°ãªã‚Šã¾ã™ã€‚å‚ç…§éŸ³å£°ã‚’ã‚ˆãèã„ã¦ã€ç¹°ã‚Šè¿”ã—ç·´ç¿’ã—ã¦ãã ã•ã„ã€‚",
                "score": round(similarity_score, 1)
            })
        
        # ãƒ¬ãƒ™ãƒ«åˆ¥ã®è¿½åŠ ã‚¢ãƒ‰ãƒã‚¤ã‚¹
        if user_level == "beginner":
            additional_tips = "ãƒã‚¤ãƒ†ã‚£ãƒ–ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ã®éŸ³å£°ã‚’èã„ã¦ã€ç¹°ã‚Šè¿”ã—ç·´ç¿’ã—ã¾ã—ã‚‡ã†ã€‚"
        elif user_level == "intermediate":
            additional_tips = "ç´°ã‹ã„éŸ³ã®é•ã„ã‚„ã‚¤ãƒ³ãƒˆãƒãƒ¼ã‚·ãƒ§ãƒ³ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã«æ³¨æ„ã—ã¾ã—ã‚‡ã†ã€‚"
        else:  # advanced
            additional_tips = "ãƒ‹ãƒ¥ã‚¢ãƒ³ã‚¹ã‚„è‡ªç„¶ãªè©±ã—æ–¹ã®æµã‚Œã‚’å®Œç’§ã«ã—ã¾ã—ã‚‡ã†ã€‚"
        
        feedback = {
            "overall": overall_message,
            "rating": overall_rating,
            "details": details,
            "tips": additional_tips
        }
        
        return feedback


def get_audio_info(file_path: str) -> Dict:
    """
    éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®åŸºæœ¬æƒ…å ±ã‚’å–å¾—
    
    Returns:
    - info: ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±
    """
    audio_data, sr = librosa.load(file_path, sr=None)
    duration = len(audio_data) / sr
    
    info = {
        "sample_rate": sr,
        "duration": duration,
        "samples": len(audio_data),
        "channels": 1 if audio_data.ndim == 1 else audio_data.shape[0]
    }
    
    return info
