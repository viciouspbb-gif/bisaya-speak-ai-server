from fastapi import FastAPI, File, UploadFile, HTTPException, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse, FileResponse
from fastapi.staticfiles import StaticFiles
import uvicorn
import os
from datetime import datetime
from pathlib import Path
import shutil
from dotenv import load_dotenv
from audio_processor import AudioProcessor
from conversation_engine import ConversationEngine, ScenarioManager
# from speech_recognition_service import SpeechRecognitionService, TextToSpeechService
import asyncio
from typing import Optional

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
load_dotenv()

app = FastAPI(
    title="Bisaya Speak AI API",
    description="AI-powered pronunciation diagnosis for Bisaya language learning",
    version="1.0.0"
)

# CORSè¨­å®šï¼ˆKotlinã‚¢ãƒ—ãƒªã‹ã‚‰ã®ã‚¢ã‚¯ã‚»ã‚¹ã‚’è¨±å¯ï¼‰
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # æœ¬ç•ªç’°å¢ƒã§ã¯é©åˆ‡ãªã‚ªãƒªã‚¸ãƒ³ã‚’æŒ‡å®š
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
UPLOAD_DIR = Path("uploads")
UPLOAD_DIR.mkdir(exist_ok=True)

# å‚ç…§éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
REFERENCE_DIR = Path("reference_audio")
REFERENCE_DIR.mkdir(exist_ok=True)

# AudioProcessorã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
audio_processor = AudioProcessor()

# AIä¼šè©±ã‚¨ãƒ³ã‚¸ãƒ³ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ï¼ˆç’°å¢ƒå¤‰æ•°ã‹ã‚‰APIã‚­ãƒ¼ã‚’å–å¾—ï¼‰
try:
    conversation_engine = ConversationEngine()
    print("âœ“ Conversation Engine initialized")
except Exception as e:
    print(f"âš  Conversation Engine initialization failed: {e}")
    print("  Set GEMINI_API_KEY environment variable to enable AI conversation features")
    conversation_engine = None

# ã‚·ãƒŠãƒªã‚ªãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼
scenario_manager = ScenarioManager()

# éŸ³å£°èªè­˜ãƒ»åˆæˆã‚µãƒ¼ãƒ“ã‚¹ï¼ˆAIä¼šè©±ã§ã¯ä¸è¦ãªã®ã§ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆï¼‰
# speech_recognition_service = SpeechRecognitionService()
# text_to_speech_service = TextToSpeechService()


@app.get("/")
@app.head("/")
async def root():
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ç”¨ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼ˆGET/HEADãƒ¡ã‚½ãƒƒãƒ‰å¯¾å¿œï¼‰"""
    return {
        "status": "ok",
        "message": "Bisaya Speak AI is running",
        "version": "1.0.0"
    }


def get_reference_audio_path(word: str) -> Path:
    """
    å˜èªã«å¯¾å¿œã™ã‚‹å‚ç…§éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’å–å¾—
    
    Parameters:
    - word: å˜èªã¾ãŸã¯ãƒ•ãƒ¬ãƒ¼ã‚º
    
    Returns:
    - reference_path: å‚ç…§éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
    """
    # å˜èªã‚’ãƒ•ã‚¡ã‚¤ãƒ«åã«å¤‰æ›ï¼ˆã‚¹ãƒšãƒ¼ã‚¹ã‚’ã‚¢ãƒ³ãƒ€ãƒ¼ã‚¹ã‚³ã‚¢ã«ã€è¨˜å·ã‚’å‰Šé™¤ï¼‰
    safe_word = word.lower().replace(" ", "_").replace("'", "").replace(",", "").replace("?", "").replace("!", "").replace(".", "").replace("-", "_")
    
    # è¤‡æ•°ã®æ‹¡å¼µå­ã‚’è©¦ã™ï¼ˆMP3å„ªå…ˆã€æ¬¡ã«WAVï¼‰
    for ext in [".mp3", ".wav", ".m4a", ".ogg"]:
        reference_filename = f"{safe_word}_ref{ext}"
        reference_path = REFERENCE_DIR / reference_filename
        if reference_path.exists():
            return reference_path
    
    # è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯MP3ãƒ‘ã‚¹ã‚’è¿”ã™ï¼ˆã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ç”¨ï¼‰
    return REFERENCE_DIR / f"{safe_word}_ref.mp3"


@app.post("/api/pronounce/check")
async def check_pronunciation(
    audio: UploadFile = File(...),
    word: str = Form(None),
    language: str = Form("bisaya"),
    level: str = Form("beginner")
):
    """
    ç™ºéŸ³è¨ºæ–­ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
    
    Parameters:
    - audio: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆWAV, MP3, M4A ãªã©ï¼‰
    - word: ç™ºéŸ³å¯¾è±¡ã®å˜èªï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    - language: è¨€èªï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: bisayaï¼‰
    - level: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ¬ãƒ™ãƒ«ï¼ˆbeginner/intermediate/advancedï¼‰
    
    Returns:
    - JSONå½¢å¼ã®è¨ºæ–­çµæœ
    """
    try:
        # ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ãƒã‚§ãƒƒã‚¯
        allowed_extensions = [".wav", ".mp3", ".m4a", ".ogg", ".flac", ".3gp", ".amr"]
        file_ext = os.path.splitext(audio.filename)[1].lower()
        
        if file_ext not in allowed_extensions:
            raise HTTPException(
                status_code=400,
                detail=f"Unsupported file format. Allowed: {', '.join(allowed_extensions)}"
            )
        
        # ãƒ¬ãƒ™ãƒ«ã®æ¤œè¨¼
        valid_levels = ["beginner", "intermediate", "advanced"]
        if level not in valid_levels:
            level = "beginner"
        
        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€æ™‚ä¿å­˜
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{timestamp}_{audio.filename}"
        file_path = UPLOAD_DIR / filename
        
        with file_path.open("wb") as buffer:
            shutil.copyfileobj(audio.file, buffer)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºå–å¾—
        file_size = file_path.stat().st_size
        
        # ç™ºéŸ³è¨ºæ–­ã‚’å®Ÿè¡Œ
        print(f"è¨ºæ–­ãƒªã‚¯ã‚¨ã‚¹ãƒˆ: word={word}, level={level}, file={file_path}")
        if word:
            # å‚ç…§éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’å–å¾—
            reference_path = get_reference_audio_path(word)
            print(f"å‚ç…§éŸ³å£°ãƒ‘ã‚¹: {reference_path}, exists={reference_path.exists()}")
            
            if reference_path.exists():
                # å®Ÿéš›ã®éŸ³å£°å‡¦ç†ã§ç™ºéŸ³ã‚’æ¯”è¼ƒ
                try:
                    print(f"éŸ³å£°å‡¦ç†é–‹å§‹: user={file_path}, reference={reference_path}")
                    comparison = audio_processor.compare_pronunciation(
                        str(file_path),
                        str(reference_path),
                        level
                    )
                    pronunciation_score = comparison['similarity_score']
                    feedback = comparison['feedback']
                    print(f"éŸ³å£°å‡¦ç†æˆåŠŸ: score={pronunciation_score}")
                except Exception as e:
                    import traceback
                    print(f"éŸ³å£°å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
                    print(traceback.format_exc())
                    # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ãƒ€ãƒŸãƒ¼ã‚¹ã‚³ã‚¢
                    import random
                    pronunciation_score = random.randint(75, 90)
                    print(f"ãƒ€ãƒŸãƒ¼ã‚¹ã‚³ã‚¢ä½¿ç”¨: {pronunciation_score}")
                    
                    # ãƒ€ãƒŸãƒ¼ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯
                    feedback = {
                        "overall": "ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚",
                        "rating": "ã‚¨ãƒ©ãƒ¼",
                        "details": [],
                        "tips": "ã‚‚ã†ä¸€åº¦éŒ²éŸ³ã—ã¦ãã ã•ã„ã€‚"
                    }
                
                response = {
                    "status": "success",
                    "message": "Audio file received and processed (demo mode)",
                    "data": {
                        "filename": audio.filename,
                        "saved_as": filename,
                        "file_size": file_size,
                        "word": word,
                        "language": language,
                        "level": level,
                        "pronunciation_score": pronunciation_score,
                        "feedback": feedback,
                        "comparison_details": {
                            "user_features": {"duration": 1.5, "pitch_mean": 150.0, "pitch_std": 20.0},
                            "reference_features": {"duration": 1.5, "pitch_mean": 150.0, "pitch_std": 20.0}
                        },
                        "timestamp": timestamp
                    }
                }
            else:
                # å‚ç…§éŸ³å£°ãŒãªã„å ´åˆã¯åŸºæœ¬çš„ãªåˆ†æã®ã¿
                response = {
                    "status": "success",
                    "message": "Audio file received. Reference audio not found, basic analysis performed.",
                    "data": {
                        "filename": audio.filename,
                        "saved_as": filename,
                        "file_size": file_size,
                        "word": word,
                        "language": language,
                        "level": level,
                        "pronunciation_score": None,
                        "feedback": {
                            "overall": f"Reference audio for '{word}' not found. Please upload reference audio.",
                            "rating": "N/A",
                            "details": [],
                            "tips": "Contact administrator to add reference audio for this word."
                        },
                        "timestamp": timestamp
                    }
                }
        else:
            # å˜èªãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„å ´åˆ
            response = {
                "status": "success",
                "message": "Audio file received. No word specified for comparison.",
                "data": {
                    "filename": audio.filename,
                    "saved_as": filename,
                    "file_size": file_size,
                    "word": None,
                    "language": language,
                    "level": level,
                    "pronunciation_score": None,
                    "feedback": {
                        "overall": "Please specify a word to evaluate pronunciation.",
                        "rating": "N/A",
                        "details": [],
                        "tips": "Send the 'word' parameter with your request."
                    },
                    "timestamp": timestamp
                }
            }
        
        # å‡¦ç†å¾Œã€ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ï¼ˆå¿…è¦ã«å¿œã˜ã¦ä¿æŒã‚‚å¯èƒ½ï¼‰
        # file_path.unlink()
        
        return JSONResponse(content=response)
        
    except Exception as e:
        import traceback
        error_detail = f"Error processing audio: {str(e)}\n{traceback.format_exc()}"
        print(error_detail)  # ã‚µãƒ¼ãƒãƒ¼ãƒ­ã‚°ã«è©³ç´°ã‚’å‡ºåŠ›
        raise HTTPException(status_code=500, detail=f"Error processing audio: {str(e)}")


@app.get("/api/health")
async def health_check():
    """è©³ç´°ãªãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
    return {
        "status": "healthy",
        "upload_dir_exists": UPLOAD_DIR.exists(),
        "upload_dir_writable": os.access(UPLOAD_DIR, os.W_OK),
        "timestamp": datetime.now().isoformat()
    }


@app.get("/api/reference-audio/{word}")
async def get_reference_audio(word: str):
    """å‚ç…§éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—"""
    from fastapi.responses import FileResponse
    
    # å‚ç…§éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’å–å¾—
    reference_path = get_reference_audio_path(word)
    
    if not reference_path.exists():
        raise HTTPException(status_code=404, detail=f"Reference audio not found for word: {word}")
    
    return FileResponse(
        path=str(reference_path),
        media_type="audio/mpeg",
        filename=f"{word}_ref.mp3"
    )


# ==================== AIä¼šè©±æ©Ÿèƒ½ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ ====================

@app.post("/api/conversation/session/create")
async def create_conversation_session(
    mode: str = Form(...),
    level: str = Form("beginner"),
    scenario_id: Optional[str] = Form(None)
):
    """
    æ–°ã—ã„ä¼šè©±ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ä½œæˆ
    
    Parameters:
    - mode: ä¼šè©±ãƒ¢ãƒ¼ãƒ‰ï¼ˆshadowing, word_drill, roleplay, free_talkï¼‰
    - level: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¬ãƒ™ãƒ«ï¼ˆbeginner, intermediate, advancedï¼‰
    - scenario_id: ã‚·ãƒŠãƒªã‚ªIDï¼ˆroleplayãƒ¢ãƒ¼ãƒ‰ã®å ´åˆï¼‰
    """
    if not conversation_engine:
        raise HTTPException(
            status_code=503,
            detail="Conversation engine not available. Please set GEMINI_API_KEY."
        )
    
    try:
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³IDã‚’ç”Ÿæˆ
        session_id = f"session_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ä½œæˆ
        session_info = conversation_engine.create_session(session_id, mode, level)
        
        # ãƒ­ãƒ¼ãƒ«ãƒ—ãƒ¬ã‚¤ã®å ´åˆã€ã‚·ãƒŠãƒªã‚ªæƒ…å ±ã‚’è¿½åŠ 
        if mode == "roleplay" and scenario_id:
            scenario = scenario_manager.get_scenario(scenario_id)
            if scenario:
                session_info["scenario"] = scenario
                # æœ€åˆã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç”Ÿæˆ
                first_message = scenario["opening"]
                session_info["first_message"] = first_message
        
        return JSONResponse(content={
            "status": "success",
            "data": session_info
        })
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/conversation/message")
async def send_conversation_message(
    session_id: str = Form(...),
    audio: Optional[UploadFile] = File(None),
    text: Optional[str] = Form(None)
):
    """
    ä¼šè©±ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡
    
    Parameters:
    - session_id: ã‚»ãƒƒã‚·ãƒ§ãƒ³ID
    - audio: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    - text: ãƒ†ã‚­ã‚¹ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    """
    if not conversation_engine:
        raise HTTPException(
            status_code=503,
            detail="Conversation engine not available."
        )
    
    try:
        user_message = text
        transcription = None
        
        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚‹å ´åˆã¯æ–‡å­—èµ·ã“ã—
        if audio:
            # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"{timestamp}_{audio.filename}"
            file_path = UPLOAD_DIR / filename
            
            with file_path.open("wb") as buffer:
                shutil.copyfileobj(audio.file, buffer)
            
            # éŸ³å£°èªè­˜
            recognition_result = speech_recognition_service.transcribe_audio(
                str(file_path),
                language="bisaya"
            )
            
            if recognition_result["status"] == "success":
                transcription = recognition_result["transcription"]
                user_message = transcription
        
        if not user_message:
            raise HTTPException(
                status_code=400,
                detail="Either audio or text message is required"
            )
        
        # AIå¿œç­”ã‚’ç”Ÿæˆï¼ˆéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚‚è‡ªå‹•ç”Ÿæˆã•ã‚Œã‚‹ï¼‰
        response = await conversation_engine.send_message(
            session_id,
            user_message,
            transcription
        )
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒ­ã‚°å‡ºåŠ›
        print(f"ğŸ“¤ Response: {response}")
        
        return JSONResponse(content={
            "status": "success",
            "data": response,
            "transcription": transcription
        })
        
    except Exception as e:
        import traceback
        print(traceback.format_exc())
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/conversation/session/{session_id}/summary")
async def get_session_summary(session_id: str):
    """ä¼šè©±ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ã‚µãƒãƒªãƒ¼ã‚’å–å¾—"""
    if not conversation_engine:
        raise HTTPException(
            status_code=503,
            detail="Conversation engine not available."
        )
    
    try:
        summary = conversation_engine.get_session_summary(session_id)
        return JSONResponse(content={
            "status": "success",
            "data": summary
        })
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/conversation/session/{session_id}/feedback")
async def get_session_feedback(session_id: str):
    """ä¼šè©±ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’å–å¾—"""
    if not conversation_engine:
        raise HTTPException(
            status_code=503,
            detail="Conversation engine not available."
        )
    
    try:
        feedback = conversation_engine.generate_feedback(session_id)
        return JSONResponse(content={
            "status": "success",
            "data": feedback
        })
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/scenarios")
async def list_scenarios(difficulty: Optional[str] = None):
    """ã‚·ãƒŠãƒªã‚ªä¸€è¦§ã‚’å–å¾—"""
    try:
        scenarios = scenario_manager.list_scenarios(difficulty)
        return JSONResponse(content={
            "status": "success",
            "data": scenarios
        })
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/scenarios/{scenario_id}")
async def get_scenario(scenario_id: str):
    """ç‰¹å®šã®ã‚·ãƒŠãƒªã‚ªã‚’å–å¾—"""
    try:
        scenario = scenario_manager.get_scenario(scenario_id)
        if not scenario:
            raise HTTPException(status_code=404, detail="Scenario not found")
        
        return JSONResponse(content={
            "status": "success",
            "data": scenario
        })
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/speech/transcribe")
async def transcribe_speech(
    audio: UploadFile = File(...),
    language: str = Form("bisaya")
):
    """éŸ³å£°ã‚’æ–‡å­—èµ·ã“ã—"""
    try:
        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{timestamp}_{audio.filename}"
        file_path = UPLOAD_DIR / filename
        
        with file_path.open("wb") as buffer:
            shutil.copyfileobj(audio.file, buffer)
        
        # éŸ³å£°èªè­˜
        result = speech_recognition_service.transcribe_audio(
            str(file_path),
            language=language
        )
        
        return JSONResponse(content={
            "status": "success",
            "data": result
        })
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«é…ä¿¡ç”¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒã‚¦ãƒ³ãƒˆ
audio_files_dir = Path("audio_files")
audio_files_dir.mkdir(exist_ok=True)
app.mount("/audio", StaticFiles(directory="audio_files"), name="audio")


if __name__ == "__main__":
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8000,
        reload=True
    )
